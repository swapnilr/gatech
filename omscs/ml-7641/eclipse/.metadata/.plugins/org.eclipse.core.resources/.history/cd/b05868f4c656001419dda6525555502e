package edu.gatech.ml.assignment2;

import opt.OptimizationAlgorithm;
import opt.RandomizedHillClimbing;
import opt.SimulatedAnnealing;
import opt.example.NeuralNetworkOptimizationProblem;
import opt.ga.StandardGeneticAlgorithm;
import func.nn.FeedForwardLayer;
import func.nn.FeedForwardNetwork;
import func.nn.FeedForwardNode;
import func.nn.Layer;
import func.nn.LayeredNetwork;
import func.nn.NeuralNetwork;
import func.nn.Neuron;
import func.nn.activation.HyperbolicTangentSigmoid;
import func.nn.backprop.BackPropagationNetwork;
import func.nn.backprop.BackPropagationNetworkFactory;
import shared.DataSet;
//import shared.DataSet;
import shared.DataSetDescription;
//import shared.Instance;
import shared.ErrorMeasure;
import shared.FixedIterationTrainer;
import shared.Instance;
import shared.SumOfSquaresError;

//import shared.DataSetReader;

public class DataSetReadingTest {

	public static void main(String[] args) {
		MyDataSetReader data = new MyDataSetReader("/Users/swapnilr/gatech/omscs/ml-7641/modifiedLetter.data");
		try {
			SubsettableDataSet set = data.read();
			//Vector v = i.getData();
			/*for(int k=0; k<set.size();k++) {
				Instance i = set.get(k);
				for(int d=0; d<i.size(); d++) {
					System.out.print(i.getDiscrete(d) + ", ");
				}
				System.out.println((char)('A' + i.getLabel().getDiscrete()));
			}*/
			System.out.println("Size = " + set.size());
			DataSetDescription desc = set.getDescription();
			System.out.println("AttributeCount = " + desc.getAttributeCount());
			//System.out.println(set.getInstances()[0]);
			//System.out.println(set.getInstances()[0].getLabel().getDiscrete());
			
			SubsettableDataSet trainingSet = set.getSubset(0, 16000);
			System.out.println("Size = " + trainingSet.size());
			DataSetDescription trainingDesc = trainingSet.getDescription();
			System.out.println("AttributeCount = " + trainingDesc.getAttributeCount());
			//System.out.println(trainingSet.getInstances()[0]);
			//System.out.println(trainingSet.getInstances()[0].getLabel());
			
			SubsettableDataSet testSet = set.getSubset(16000, set.size());
			System.out.println("Size = " + testSet.size());
			DataSetDescription testDesc = testSet.getDescription();
			System.out.println("AttributeCount = " + testDesc.getAttributeCount());
			
			
			//BackPropagationNetworkFactory factory = 
		    //        new BackPropagationNetworkFactory();
		    //    double[][][] data1 = {
		    //           { { 1, 1, 1, 1 }, { 0 } },
		    //           { { 1, 0, 1, 0 }, { 1 } },
		    //           { { 0, 1, 0, 1 }, { 1 } },
		    //           { { 0, 0, 0, 0 }, { 0 } }
		    //    };
		    //    Instance[] patterns = new Instance[data1.length];
		    //    for (int i = 0; i < patterns.length; i++) {
		    //       patterns[i] = new Instance(data1[i][0]);
		    //        patterns[i].setLabel(new Instance(data1[i][1]));
		    //    }
		    //    BackPropagationNetwork network = factory.createClassificationNetwork(
		    //       new int[] { 4, 3, 1 });
			
			// Input Layer
			FeedForwardLayer input = new FeedForwardLayer();
			for(int i=0;i<desc.getAttributeCount();i++) {
				input.addNode(new FeedForwardNode(new HyperbolicTangentSigmoid()));
			}
			// Hidden Layer 1
			FeedForwardLayer hidden1 = new FeedForwardLayer();
			for(int i=0;i<31;i++) {
				hidden1.addNode(new FeedForwardNode(new HyperbolicTangentSigmoid()));
			}
			// Hidden Layer 2
			FeedForwardLayer hidden2 = new FeedForwardLayer();
			for(int i=0;i<26;i++) {
				hidden2.addNode(new FeedForwardNode(new HyperbolicTangentSigmoid()));
			}
			// Ouput Layer
			FeedForwardLayer output = new FeedForwardLayer();
			for(int i=0;i<26;i++) {
				output.addNode(new FeedForwardNode(new HyperbolicTangentSigmoid()));
			}
			FeedForwardNetwork network = new FeedForwardNetwork();
			network.setInputLayer(input);
			network.addHiddenLayer(hidden1);
			network.addHiddenLayer(hidden2);
			network.setOutputLayer(output);
			network.connect();
		    ErrorMeasure measure = new SumOfSquaresError();
		    //    DataSet set1 = new DataSet(patterns);
		   NeuralNetworkOptimizationProblem nno = new NeuralNetworkOptimizationProblem(
		            trainingSet, network, measure);
		   //System.out.println(network.getLinks().size());
		   OptimizationAlgorithm o = new RandomizedHillClimbing(nno);
		   FixedIterationTrainer fit = new FixedIterationTrainer(o, 500);
		   long startTime = System.nanoTime();
		   fit.train();
           long endTime = System.nanoTime();
     	   long duration = (endTime - startTime);
     	   System.out.println(duration/1000000); 
		   
     	  /*startTime = System.nanoTime();
          SimulatedAnnealing sa = new SimulatedAnnealing(100, .95, hcp);
          fit = new FixedIterationTrainer(sa, 200000);
          fit.train();
          endTime = System.nanoTime();
          duration = (endTime - startTime);
          System.out.println(ef.value(sa.getOptimal()) + " " + duration/1000000);
          
          startTime = System.nanoTime();
          StandardGeneticAlgorithm ga = new StandardGeneticAlgorithm(200, 100, 20, gap);
          fit = new FixedIterationTrainer(ga, 1000);
          fit.train();
          endTime = System.nanoTime();
          duration = (endTime - startTime);
          System.out.println(ef.value(ga.getOptimal()) + " " + duration/1000000);*/
     	   
		   Instance opt = o.getOptimal();
		   network.setWeights(opt.getData());
		   int total = 0;
		   int correct = 0;
		   Instance[] patterns = testSet.getInstances();
		   for (int i = 0; i < patterns.length; i++) {
		     network.setInputValues(patterns[i].getData());
		     network.run();
		     if(patterns[i].getLabel().getData().argMax() == network.getOutputValues().argMax()) {
		    	 correct++;
		     }
		     total++;
		   }
		   System.out.println((double)correct/(double)total);
		} catch (Exception e) {
			e.printStackTrace();
		}

	}

}
