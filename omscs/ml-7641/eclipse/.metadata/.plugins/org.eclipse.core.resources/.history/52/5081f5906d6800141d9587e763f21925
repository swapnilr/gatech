package edu.gatech.ml.assignment3;

import java.io.BufferedReader;
import java.io.FileNotFoundException;
import java.io.FileReader;

import weka.attributeSelection.AttributeSelection;
import weka.attributeSelection.InfoGainAttributeEval;
import weka.attributeSelection.Ranker;
import weka.clusterers.AbstractClusterer;
import weka.clusterers.EM;
import weka.clusterers.SimpleKMeans;
import weka.core.Instances;
import weka.core.converters.ArffLoader.ArffReader;
import weka.filters.Filter;
import weka.filters.unsupervised.attribute.PrincipalComponents;

public class MainExperiment {

	public static void main(String[] args) {

		try {
			String[] filenames = new String[2];
			filenames[0] = "/Users/swapnilr/gatech/omscs/ml-7641/letter.arff";
			filenames[1] = "/Users/swapnilr/gatech/omscs/ml-7641/waveform-5000.arff";
			int[] sizes = new int[2];
			sizes[0] = 26;
			sizes[1] = 3;
			
			/*for(int i=0; i < filenames.length; i++) {
				// Get training data
				System.out.println("Running experiments for " + filenames[i]);
				
				BufferedReader reader = new BufferedReader(new FileReader(filenames[i]));
				ArffReader arff = new ArffReader(reader);
				Instances trainingData = arff.getData();
				trainingData.deleteAttributeAt(trainingData.numAttributes() - 1);
				
				BufferedReader reader2 = new BufferedReader(new FileReader(filenames[i]));
				ArffReader arff2 = new ArffReader(reader2);
				Instances validationData = arff2.getData();
				validationData.setClassIndex(validationData.numAttributes() - 1);
				
				runBothClusteringExperiments(trainingData, validationData, sizes[i]);
				
			}*/
			
			for(int i=0; i < filenames.length; i++) {
				// Get training data
				System.out.println("Running PCA experiments for " + filenames[i]);
				
				BufferedReader reader = new BufferedReader(new FileReader(filenames[i]));
				ArffReader arff = new ArffReader(reader);
				Instances trainingData = arff.getData();
				
				trainingData.setClassIndex(trainingData.numAttributes() - 1);
				
				PrincipalComponents pca = new PrincipalComponents();
				pca.setInputFormat(trainingData);
				
				trainingData = Filter.useFilter(trainingData, pca);
				
				trainingData.setClassIndex(-1);
				trainingData.deleteAttributeAt(trainingData.numAttributes() - 1);
				
				BufferedReader reader2 = new BufferedReader(new FileReader(filenames[i]));
				ArffReader arff2 = new ArffReader(reader2);
				Instances validationData = arff2.getData();
				validationData.setClassIndex(validationData.numAttributes() - 1);
				validationData = Filter.useFilter(validationData, pca);
				
				runBothClusteringExperiments(trainingData, validationData, sizes[i]);
				
			}
			
		} catch (Exception e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		
		//Both Datasets
		  // Nothing + 4 Dimensionality Reduction
		    // Clustering experiments - EM + K-means {Various possibilites for 1
		
		// Data Set 1
		  // 4 Dimensionality Reduction
		    // NN
		  // 2 Clustering Algorithms
		    // NN {Various possibilities}
		
		
	}
	
	public void runExperiments(Filter f) throws Exception {
		String[] filenames = new String[2];
		filenames[0] = "/Users/swapnilr/gatech/omscs/ml-7641/letter.arff";
		filenames[1] = "/Users/swapnilr/gatech/omscs/ml-7641/waveform-5000.arff";
		int[] sizes = new int[2];
		sizes[0] = 26;
		sizes[1] = 3;
		
		for(int i=0; i < filenames.length; i++) {
			// Get training data
			System.out.println("Running experiments for " + filenames[i] + " with Filter " + f.getClass());
			
			BufferedReader reader = new BufferedReader(new FileReader(filenames[i]));
			ArffReader arff = new ArffReader(reader);
			Instances trainingData = arff.getData();
			
			trainingData.setClassIndex(trainingData.numAttributes() - 1);
			
			f.setInputFormat(trainingData);
			
			trainingData = Filter.useFilter(trainingData, f);
			
			trainingData.setClassIndex(-1);
			trainingData.deleteAttributeAt(trainingData.numAttributes() - 1);
			
			BufferedReader reader2 = new BufferedReader(new FileReader(filenames[i]));
			ArffReader arff2 = new ArffReader(reader2);
			Instances validationData = arff2.getData();
			validationData.setClassIndex(validationData.numAttributes() - 1);
			validationData = Filter.useFilter(validationData, f);
			
			runBothClusteringExperiments(trainingData, validationData, sizes[i]);
			
		}

		
	}
	
	public static void runBothClusteringExperiments(Instances trainingData, Instances validationData, int numLabels) throws Exception {
		AbstractClusterer[] clusterers = new AbstractClusterer[2];
		SimpleKMeans km = new SimpleKMeans();
		km.setNumClusters(numLabels);
		clusterers[0] = km;
		EM em = new EM();
		em.setNumClusters(numLabels);
		clusterers[1] = em;
		ClusteringExperiment exp;
		for(AbstractClusterer c: clusterers) {
			System.out.println("Running Experiment for " + c.getClass() + " with number of labels = " + numLabels);
			exp = new ClusteringExperiment(c, numLabels);
			exp.setTiming(true);
			exp.setSet(validationData);
			exp.runExperiment(trainingData);
		}
		
		
	}
	
	
	
}
