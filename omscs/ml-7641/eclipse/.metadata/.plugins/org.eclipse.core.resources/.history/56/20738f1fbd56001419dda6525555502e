package edu.gatech.ml.assignment2;

import opt.OptimizationAlgorithm;
import opt.RandomizedHillClimbing;
import opt.example.NeuralNetworkOptimizationProblem;
import func.nn.Layer;
import func.nn.Neuron;
import func.nn.backprop.BackPropagationNetwork;
import func.nn.backprop.BackPropagationNetworkFactory;
import shared.DataSet;
//import shared.DataSet;
import shared.DataSetDescription;
//import shared.Instance;
import shared.ErrorMeasure;
import shared.FixedIterationTrainer;
import shared.Instance;
import shared.SumOfSquaresError;

//import shared.DataSetReader;

public class DataSetReadingTest {

	public static void main(String[] args) {
		MyDataSetReader data = new MyDataSetReader("/Users/swapnilr/gatech/omscs/ml-7641/modifiedLetter.data");
		try {
			SubsettableDataSet set = data.read();
			//Vector v = i.getData();
			/*for(int k=0; k<set.size();k++) {
				Instance i = set.get(k);
				for(int d=0; d<i.size(); d++) {
					System.out.print(i.getDiscrete(d) + ", ");
				}
				System.out.println((char)('A' + i.getLabel().getDiscrete()));
			}*/
			System.out.println("Size = " + set.size());
			DataSetDescription desc = set.getDescription();
			System.out.println("AttributeCount = " + desc.getAttributeCount());
			System.out.println(set.getLabelDataSet().getDescription().getAttributeCount());
			
			SubsettableDataSet trainingSet = set.getSubset(0, 16000);
			System.out.println("Size = " + trainingSet.size());
			DataSetDescription trainingDesc = trainingSet.getDescription();
			System.out.println("AttributeCount = " + trainingDesc.getAttributeCount());
			
			SubsettableDataSet testSet = set.getSubset(16000, set.size());
			System.out.println("Size = " + testSet.size());
			DataSetDescription testDesc = testSet.getDescription();
			System.out.println("AttributeCount = " + testDesc.getAttributeCount());
			
			
			//BackPropagationNetworkFactory factory = 
		    //        new BackPropagationNetworkFactory();
		    //    double[][][] data1 = {
		    //           { { 1, 1, 1, 1 }, { 0 } },
		    //           { { 1, 0, 1, 0 }, { 1 } },
		    //           { { 0, 1, 0, 1 }, { 1 } },
		    //           { { 0, 0, 0, 0 }, { 0 } }
		    //    };
		    //    Instance[] patterns = new Instance[data1.length];
		    //    for (int i = 0; i < patterns.length; i++) {
		    //       patterns[i] = new Instance(data1[i][0]);
		    //        patterns[i].setLabel(new Instance(data1[i][1]));
		    //    }
		    //    BackPropagationNetwork network = factory.createClassificationNetwork(
		    //       new int[] { 4, 3, 1 });
			
			// Input Layer
			Layer input = new Layer();
			for(int i=0;i<desc.getAttributeCount();i++) {
				input.addNode(new Neuron());
			}
			// Hidden Layer 1
			
			// Hidden Layer 2
			// Ouput Layer
			Layer output = new Layer();
			for(int i=0; i<)
		        ErrorMeasure measure = new SumOfSquaresError();
		    //    DataSet set1 = new DataSet(patterns);
		        NeuralNetworkOptimizationProblem nno = new NeuralNetworkOptimizationProblem(
		            set1, network, measure);
		        OptimizationAlgorithm o = new RandomizedHillClimbing(nno);
		        FixedIterationTrainer fit = new FixedIterationTrainer(o, 5000);
		        fit.train();
		        Instance opt = o.getOptimal();
		        network.setWeights(opt.getData());
		        for (int i = 0; i < patterns.length; i++) {
		            network.setInputValues(patterns[i].getData());
		            network.run();
		            System.out.println("~~");
		            System.out.println(patterns[i].getLabel());
		            System.out.println(network.getOutputValues());
		        }
			
			//System.out.println(desc.getAttributeTypes()[0].toString());
		} catch (Exception e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}

	}

}
